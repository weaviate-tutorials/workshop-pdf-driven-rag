{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5240041f",
   "metadata": {},
   "source": [
    "# Welcome! \n",
    "\n",
    "While we wait to get started:\n",
    "\n",
    "*Please follow the setup instructions in README to get your environment ready*\n",
    "\n",
    "https://github.com/weaviate-tutorials/workshop-pdf-driven-rag/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb67f",
   "metadata": {},
   "source": [
    "![assets/workshop_cover.jpg](assets/workshop_cover.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83e50b",
   "metadata": {},
   "source": [
    "![assets/about_weaviate.png](assets/about_weaviate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1150d8c8",
   "metadata": {},
   "source": [
    "![assets/workshop_agenda.jpg](assets/workshop_agenda.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06d56d3",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Load environment variables. If you haven't set up your `.env` file, please refer to the [README](README.md).\n",
    "\n",
    "In the live session, your instructor may provide you with temporary keys to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84232a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556603ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.getenv(\"COHERE_API_KEY\")[:5])\n",
    "print(os.getenv(\"ANTHROPIC_API_KEY\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de5370",
   "metadata": {},
   "source": [
    "## Working with PDFs - an introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8693ef",
   "metadata": {},
   "source": [
    "### Get text from PDFs\n",
    "\n",
    "PDFs contain rich formatting:\n",
    "\n",
    "<img src=\"data/imgs/howto-free-threading-python_2_of_4.png\" height=\"500px\" />\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_34_of_80.jpg\" height=\"500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de250ab",
   "metadata": {},
   "source": [
    "Modern libraries can preserve document structure while converting to text format, making the text easier to process while maintaining semantic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9010e68",
   "metadata": {},
   "source": [
    "Let's try a popular library, `docling`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c728a",
   "metadata": {},
   "source": [
    "Here's how we can convert PDFs into text files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a44a12-40dc-4e92-af6e-0a65d2e11d8b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 437,
      "type": "stream"
     },
     "1": {
      "height": 143,
      "type": "stream"
     },
     "2": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "\n",
    "def parse_pdf(input_doc_path: Path, output_dir: Path):\n",
    "    doc_converter = DocumentConverter()\n",
    "    conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "    # Save markdown\n",
    "    filename = input_doc_path.stem\n",
    "    md_filepath = output_dir / f\"{filename}-parsed-text.md\"\n",
    "    if not md_filepath.exists():\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Saving parsed text to {md_filepath}\")\n",
    "        with md_filepath.open(\"w\", encoding=\"utf-8\") as md_file:\n",
    "            md_file.write(conv_res.document.export_to_markdown())\n",
    "    else:\n",
    "        print(f\"Parsed text already exists at {md_filepath}, skipping text extraction.\")\n",
    "    return md_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"data/pdfs\")\n",
    "output_dir = Path(\"data/parsed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "input_pdf_name = \"howto-free-threading-python.pdf\"\n",
    "input_doc_path = data_folder / input_pdf_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f604b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the parser function\n",
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8bd52f",
   "metadata": {},
   "source": [
    "Inspect the converted file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6cf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_txt = md_filepath.read_text()\n",
    "\n",
    "# Print some part of the parsed text:\n",
    "# ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b62b17",
   "metadata": {},
   "source": [
    "### Chunking\n",
    "\n",
    "Chunking breaks documents into smaller, manageable pieces while preserving context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50681c2",
   "metadata": {},
   "source": [
    "![assets/chunking_why.png](assets/chunking_why.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bddf09",
   "metadata": {},
   "source": [
    "#### RAG - Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a848949",
   "metadata": {},
   "source": [
    "![assets/llm_2_rag_basic.png](assets/llm_2_rag_basic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66bb32",
   "metadata": {},
   "source": [
    "What does this have to do with chunking? \n",
    "\n",
    "Each \"chunk\" becomes a \"unit\" of context to feed into a RAG input!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ec2ff",
   "metadata": {},
   "source": [
    "### Chunking strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99973c13",
   "metadata": {},
   "source": [
    "Different chunking strategies serve different use cases. \n",
    "\n",
    "![assets/chunking_methods.png](assets/chunking_methods.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c3c26",
   "metadata": {},
   "source": [
    "Let's try a few options:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddfa414",
   "metadata": {},
   "source": [
    "#### Chunk by text length with overlap\n",
    "\n",
    "Overlapping chunks help maintain context across boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3329d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_by_length_with_overlap(src_text: str, chunk_length: int = 500, overlap: int = 100) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split text into chunks of approximately `chunk_length` characters.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(src_text), chunk_length):\n",
    "        chunks.append(src_text[i:i + chunk_length + overlap])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc39a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try chunking using the get_chunks_by_length_with_overlap method\n",
    "# ADD YOUR CODE HERE\n",
    "\n",
    "# Have a look at some of the chunks\n",
    "display(chunks[:5])\n",
    "print(len(chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694e768",
   "metadata": {},
   "source": [
    "#### Chunk using markers\n",
    "\n",
    "Using document markers (like headers) creates chunks that respect natural document boundaries. \n",
    "\n",
    "This approach preserves semantic structure and is ideal for documents with clear hierarchical organization like reports, manuals, or academic papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35daea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_using_markers(src_text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split the source text into chunks using markers.\n",
    "    \"\"\"\n",
    "    marker = \"\\n##\"\n",
    "\n",
    "    # Split by marker and reconstruct with markers (except first chunk)\n",
    "    parts = src_text.split(marker)\n",
    "    chunks = []\n",
    "\n",
    "    # Add first chunk if it exists and isn't empty\n",
    "    if parts[0].strip():\n",
    "        chunks.append(parts[0].strip())\n",
    "\n",
    "    # Add remaining chunks with markers reattached\n",
    "    for part in parts[1:]:\n",
    "        if part.strip():\n",
    "            chunks.append(marker + part.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd11080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try chunking using the marker-based method\n",
    "# ADD YOUR CODE HERE\n",
    "\n",
    "# Have a look at some of the chunks\n",
    "display(chunks[:5])\n",
    "print(len(chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0841b2",
   "metadata": {},
   "source": [
    "### Choosing the right strategy\n",
    "\n",
    "The best chunking strategy depends on your use case. \n",
    "\n",
    "Marker-based chunking excels with structured documents - but in some cases, it may not work as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_file_2 = Path(\"data/parsed/hai_ai_index_report_2025_chapter_2-parsed-text.md\")\n",
    "md_text_2 = md_file_2.read_text(encoding=\"utf-8\")\n",
    "get_chunks_using_markers(md_text_2)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96380962",
   "metadata": {},
   "source": [
    "Here, the page headers are mistakenly interpreted as headings, which confuses our structure. \n",
    "\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_05_of_80.jpg\" height=\"500px\" />\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_06_of_80.jpg\" height=\"500px\" />\n",
    "\n",
    "As a result, a length-based chunking method tends to be quite robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343c7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "workshop-pdf-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
