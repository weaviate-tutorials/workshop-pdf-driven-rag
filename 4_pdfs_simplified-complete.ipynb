{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6a45f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd7f076",
   "metadata": {},
   "source": [
    "## Working with PDFs as images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b9a25",
   "metadata": {},
   "source": [
    "### Approach 2: Use the entire page!\n",
    "\n",
    "How do we mentally split PDFs? We usually think of them as a set of pages. We can do the same with PDFs, by embedding the entire page!\n",
    "\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_34_of_80.jpg\" width=\"200px\" />\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_58_of_80.jpg\" width=\"200px\" />\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_69_of_80.jpg\" width=\"200px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47094cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.32.5\",\n",
    "    headers={\n",
    "        \"X-Cohere-Api-Key\": os.getenv(\"COHERE_API_KEY\"),\n",
    "    },\n",
    "    environment_variables={\n",
    "        \"LOG_LEVEL\": \"error\",                   # Reduce amount of logs\n",
    "        \"ENABLE_API_BASED_MODULES\": \"true\",     # Enable API-based modules like multi2vec-cohere\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdf0c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"load_all_shards\",\"build_git_commit\":\"08d409a988\",\"build_go_version\":\"go1.25.0\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.32.5\",\"level\":\"error\",\"msg\":\"failed to load all shards: context canceled\",\"time\":\"2025-09-15T20:52:55+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "client.collections.delete(\"Pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e16e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x128a62410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure, Tokenization\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Pages\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"document_title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"page_image\",\n",
    "            data_type=DataType.BLOB,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"filename\",\n",
    "            data_type=DataType.TEXT,\n",
    "            tokenization=Tokenization.FIELD\n",
    "        ),\n",
    "    ],\n",
    "    vector_config=[\n",
    "        # Add `Configure.Vectors.multi2vec_cohere` vector to the collection with:\n",
    "        # name: \"default\", source properties: [\"page_image\"], and model: \"embed-v4.0\"\n",
    "        # BEGIN_SOLUTION\n",
    "        Configure.Vectors.multi2vec_cohere(\n",
    "            name=\"default\",\n",
    "            image_fields=[\"page_image\"],\n",
    "            model=\"embed-v4.0\"\n",
    "        )\n",
    "        # END_SOLUTION\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b2e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = client.collections.get(\"Pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee6dd2",
   "metadata": {},
   "source": [
    "Load pre-computed vectors & metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8566e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"data/embeddings/hai_embeddings_metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "embeddings = np.load(\"data/embeddings/hai_image_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5ad58",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a58a9a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:00, 1187.07it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "with pages.batch.fixed_size(batch_size=100) as batch:\n",
    "    for i, embedding in tqdm(enumerate(embeddings)):\n",
    "        filepath = Path(metadata[\"image_paths\"][i])\n",
    "        image = filepath.read_bytes()\n",
    "        base64_image = base64.b64encode(image).decode('utf-8')\n",
    "        obj = {\n",
    "            \"document_title\": \"Stanford HAI Report 2025\",\n",
    "            \"page_image\": base64_image,\n",
    "            \"filename\": filepath.name\n",
    "        }\n",
    "\n",
    "        # Add object to batch for import with (batch.add_object())\n",
    "        # This time, manually provide the vector with `{\"default\": embedding}`\n",
    "        # BEGIN_SOLUTION\n",
    "        batch.add_object(\n",
    "            properties=obj,\n",
    "            vector={\"default\": embedding}\n",
    "        )\n",
    "        # END_SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ba2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.generate import GenerativeConfig, GenerativeParameters\n",
    "\n",
    "prompt = GenerativeParameters.grouped_task(\n",
    "    prompt=\"What advances has there been in autonomous driving in the last few years?\",\n",
    "    image_properties=[\"page_image\"],  # Property containing images in Weaviate\n",
    ")\n",
    "\n",
    "\n",
    "response = pages.generate.near_text(\n",
    "    # Try a RAG query with:\n",
    "    # query (what to search for): \"How to clean the drain pump\" and\n",
    "    # limit (how many objects to fetch): 3\n",
    "    # grouped_task (prompt): prompt defined above\n",
    "    # BEGIN_SOLUTION\n",
    "    query=\"autonomous driving advances\",\n",
    "    limit=3,\n",
    "    grouped_task=prompt,\n",
    "    # END_SOLUTION\n",
    "    # Runtime definition of what generative AI model provider to use\n",
    "    generative_provider=GenerativeConfig.anthropic(\n",
    "        model=\"claude-3-5-haiku-latest\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a683418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the images, here are key advances in autonomous driving over recent years:\n",
      "\n",
      "1. Vehicle Developments:\n",
      "- Tesla unveiled the Cybercab, a two-passenger autonomous vehicle without a steering wheel or pedals, set for production in 2026\n",
      "- Baidu launched its Apollo Go robotaxi, the RT6, across multiple cities in China\n",
      "- Waymo has expanded operations to four major U.S. cities (Phoenix, San Francisco, Los Angeles, Austin)\n",
      "\n",
      "2. Technological Improvements:\n",
      "- New benchmarks for evaluating self-driving capabilities have been introduced, like:\n",
      "  - OpenAD: First real-world, open-world autonomous driving benchmark for 3D object detection\n",
      "  - Bench2Drive: A comprehensive benchmark providing more realistic, closed-loop testing simulation\n",
      "\n",
      "3. Deployment and Scale:\n",
      "- Commercial robotaxi fleets are now operating in several cities\n",
      "- Waymo provides 150,000 paid rides per week, covering over a million miles\n",
      "- Baidu reported 988,000 rides across China in Q3 2024, with a 20% year-over-year increase\n",
      "- China is testing driverless cars across 16 cities\n",
      "\n",
      "4. Safety Performance:\n",
      "- Emerging research suggests self-driving cars may be safer than human-driven vehicles\n",
      "- Waymo vehicles showed fewer incidents per million miles, including:\n",
      "  - 3.65 fewer police-reported crashes\n",
      "  - 1.42 fewer airbag deployments\n",
      "  - 3.16 fewer crashes with reported injuries\n"
     ]
    }
   ],
   "source": [
    "print(response.generative.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3225057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: hai_ai_index_report_2025_chapter_2_77_of_80.jpg\n",
      "Filename: hai_ai_index_report_2025_chapter_2_78_of_80.jpg\n",
      "Filename: hai_ai_index_report_2025_chapter_2_76_of_80.jpg\n"
     ]
    }
   ],
   "source": [
    "for o in response.objects:\n",
    "    print(f\"Filename: {o.properties['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e89bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"build_git_commit\":\"08d409a988\",\"build_go_version\":\"go1.25.0\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.32.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-09-15T20:53:10+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdd760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-pdf-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
