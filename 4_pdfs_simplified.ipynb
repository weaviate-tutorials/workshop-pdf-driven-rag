{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a45f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd7f076",
   "metadata": {},
   "source": [
    "## Working with PDFs as images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607b9a25",
   "metadata": {},
   "source": [
    "### Approach 2: Use the entire page!\n",
    "\n",
    "How do we mentally split PDFs? We usually think of them as a set of pages. We can do the same with PDFs, by embedding the entire page!\n",
    "\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_34_of_80.jpg\" width=\"200px\" />\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_58_of_80.jpg\" width=\"200px\" />\n",
    "<img src=\"data/imgs/hai_ai_index_report_2025_chapter_2_69_of_80.jpg\" width=\"200px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47094cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Helper function to connect to Weaviate\n",
    "client = utils.connect_to_weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"Pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e16e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure, Tokenization\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Pages\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"document_title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"page_image\",\n",
    "            data_type=DataType.BLOB,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"filename\",\n",
    "            data_type=DataType.TEXT,\n",
    "            tokenization=Tokenization.FIELD\n",
    "        ),\n",
    "    ],\n",
    "    vector_config=[\n",
    "        # Add `Configure.Vectors.multi2vec_cohere` vector to the collection with:\n",
    "        # name: \"default\", source properties: [\"page_image\"], and model: \"embed-v4.0\"\n",
    "        # ADD YOUR CODE HERE\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = client.collections.get(\"Pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee6dd2",
   "metadata": {},
   "source": [
    "Load pre-computed vectors & metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8566e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"data/embeddings/hai_embeddings_metadata.json\", \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "embeddings = np.load(\"data/embeddings/hai_image_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5ad58",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "with pages.batch.fixed_size(batch_size=100) as batch:\n",
    "    for i, embedding in tqdm(enumerate(embeddings)):\n",
    "        filepath = Path(metadata[\"image_paths\"][i])\n",
    "        image = filepath.read_bytes()\n",
    "        base64_image = base64.b64encode(image).decode('utf-8')\n",
    "        obj = {\n",
    "            \"document_title\": \"Stanford HAI Report 2025\",\n",
    "            \"page_image\": base64_image,\n",
    "            \"filename\": filepath.name\n",
    "        }\n",
    "\n",
    "        # Add object to batch for import with (batch.add_object())\n",
    "        # This time, manually provide the vector with `{\"default\": embedding}`\n",
    "        # ADD YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.generate import GenerativeConfig, GenerativeParameters\n",
    "\n",
    "prompt = GenerativeParameters.grouped_task(\n",
    "    prompt=\"What advances has there been in autonomous driving in the last few years?\",\n",
    "    image_properties=[\"page_image\"],  # Property containing images in Weaviate\n",
    ")\n",
    "\n",
    "\n",
    "response = pages.generate.near_text(\n",
    "    # Try a RAG query with:\n",
    "    # query (what to search for): \"How to clean the drain pump\" and\n",
    "    # limit (how many objects to fetch): 3\n",
    "    # grouped_task (prompt): prompt defined above\n",
    "    # ADD YOUR CODE HERE\n",
    "    # Runtime definition of what generative AI model provider to use\n",
    "    generative_provider=GenerativeConfig.anthropic(\n",
    "        model=\"claude-3-5-haiku-latest\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a683418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.generative.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in response.objects:\n",
    "    print(f\"Filename: {o.properties['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e89bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdd760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-pdf-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
