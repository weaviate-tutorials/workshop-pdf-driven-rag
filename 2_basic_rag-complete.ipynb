{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5b434e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f86938",
   "metadata": {},
   "source": [
    "## Basic RAG with Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5caf639",
   "metadata": {},
   "source": [
    "Now - let's try performing RAG with the chunks that we've created. \n",
    "\n",
    "We will:\n",
    "- Load & chunk a document\n",
    "- Add the chunks to Weaviate, and generate vectors\n",
    "- And perform RAG\n",
    "\n",
    "We assume some familiarity with Weaviate here. \n",
    "\n",
    "(If not, check out the [Weaviate Quickstart](https://docs.weaviate.io/weaviate/quickstart), or ask questions in the live session!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfefcb7",
   "metadata": {},
   "source": [
    "### Load and chunk a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2679d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_chunks_using_markers(src_text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split the source text into chunks using markers.\n",
    "    \"\"\"\n",
    "    marker = \"\\n##\"\n",
    "\n",
    "    # Split by marker and reconstruct with markers (except first chunk)\n",
    "    parts = src_text.split(marker)\n",
    "    chunks = []\n",
    "\n",
    "    # Add first chunk if it exists and isn't empty\n",
    "    if parts[0].strip():\n",
    "        chunks.append(parts[0].strip())\n",
    "\n",
    "    # Add remaining chunks with markers reattached\n",
    "    for part in parts[1:]:\n",
    "        if part.strip():\n",
    "            chunks.append(marker + part.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "md_file = Path(\"data/parsed/hai_ai_index_report_2025_chapter_2-parsed-text.md\")\n",
    "md_text = md_file.read_text(encoding=\"utf-8\")\n",
    "chunk_texts = get_chunks_using_markers(md_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5b1f4",
   "metadata": {},
   "source": [
    "### Set up Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f65c42",
   "metadata": {},
   "source": [
    "Connection code looks like this:\n",
    "\n",
    "```python\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.32.5\",\n",
    "    headers={\n",
    "        \"X-Anthropic-Api-Key\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "        \"X-Cohere-Api-Key\": os.getenv(\"COHERE_API_KEY\")\n",
    "    },\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fcf6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import utils\n",
    "\n",
    "# Helper function to connect to Weaviate\n",
    "client = utils.connect_to_weaviate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a68ec",
   "metadata": {},
   "source": [
    "### Set up a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac3093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"Chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bce4dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x10e3b6e00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure, Tokenization\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Chunks\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"document_title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk_number\",\n",
    "            data_type=DataType.INT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"filename\",\n",
    "            data_type=DataType.TEXT,\n",
    "            tokenization=Tokenization.FIELD\n",
    "        ),\n",
    "    ],\n",
    "    vector_config=[\n",
    "        # Add `Configure.Vectors.text2vec_cohere` vector to the collection with:\n",
    "        # name: \"default\", source properties: [\"document_title\", \"chunk\"], model: \"embed-v4.0\"\n",
    "        # BEGIN_SOLUTION\n",
    "        Configure.Vectors.text2vec_cohere(\n",
    "            name=\"default\",\n",
    "            source_properties=[\"document_title\", \"chunk\"],\n",
    "            model=\"embed-v4.0\"\n",
    "        )\n",
    "        # END_SOLUTION\n",
    "    ],\n",
    "    generative_config=Configure.Generative.anthropic(\n",
    "        model=\"claude-3-5-haiku-latest\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f24e74",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a975565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = client.collections.get(\"Chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa01ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266it [00:00, 15871.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with chunks.batch.fixed_size(batch_size=100) as batch:\n",
    "    for i, chunk_text in tqdm(enumerate(chunk_texts)):\n",
    "        obj = {\n",
    "            \"document_title\": \"Stanford HAI Report 2025\",\n",
    "            \"filename\": \"data/pdfs/hai_ai_index_report_2025_chapter_2.pdf\",\n",
    "            \"chunk\": chunk_text,\n",
    "            \"chunk_number\": i + 1,\n",
    "        }\n",
    "\n",
    "        # Add object to batch for import with (batch.add_object())\n",
    "        # BEGIN_SOLUTION\n",
    "        batch.add_object(\n",
    "            properties=obj\n",
    "        )\n",
    "        # END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592d8f5",
   "metadata": {},
   "source": [
    "### RAG queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query response:\n",
      "Based on the provided text, here are the key use cases and benefits of agentic AI mentioned:\n",
      "\n",
      "Use Cases:\n",
      "1. Academic research assistance\n",
      "2. Scheduling meetings\n",
      "3. Online shopping facilitation\n",
      "4. Vacation booking\n",
      "5. Operating in household and gaming environments\n",
      "6. Interacting with mobile and web applications\n",
      "7. Visual design tasks (like CSS debugging)\n",
      "\n",
      "Benefits:\n",
      "1. Ability to operate autonomously or semi-autonomously in specific environments\n",
      "2. Capability to accomplish complex goals across diverse and dynamic contexts\n",
      "3. Increasing multimodality, allowing interaction across different types of environments\n",
      "4. Potential to extend AI's functionality beyond traditional linguistic interactions\n",
      "\n",
      "The text also notes that while agentic AI is promising, current models are still far from being ready for direct deployment, with top-performing models achieving only around 36.2% success rate in benchmarks.\n"
     ]
    }
   ],
   "source": [
    "# Try a RAG query with:\n",
    "# query (what to search for): \"Agentic AI use cases\" and\n",
    "# grouped_task (prompt): \"Briefly, what use cases and benefits of agentic AI are mentioned here?\"\n",
    "# limit (how many objects to fetch): 10\n",
    "# BEGIN_SOLUTION\n",
    "response = chunks.generate.hybrid(\n",
    "    query=\"Agentic AI use cases\",\n",
    "    limit=5,\n",
    "    grouped_task=\"Briefly, what use cases and benefits of agentic AI are mentioned here?\"\n",
    ")\n",
    "# END_SOLUTION\n",
    "\n",
    "print(\"Query response:\")\n",
    "print(response.generative.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cc6cbf",
   "metadata": {},
   "source": [
    "### Recap - what's happening under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d4730",
   "metadata": {},
   "source": [
    "![assets/llm_3_rag_weaviate.png](assets/llm_3_rag_weaviate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72249075",
   "metadata": {},
   "source": [
    "We can review the passages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a151a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting passages:\n",
      "\n",
      "> Object: bed7cd7c-bef4-4000-8187-2b37f2b7aa8f:\n",
      "\n",
      "##Gemini 2.0 in an agentic work fl ow\n",
      "\n",
      "Source: AI Index, 2025\n",
      "\n",
      "<!-- image -->...\n",
      "\n",
      "> Object: 5bba3d76-5623-458c-9388-5ff6329a5e78:\n",
      "\n",
      "##2.8 AI Agents Chapter 2: Technical Performance\n",
      "\n",
      "AI agents, autonomous or semiautonomous systems designed to operate within  speci fi c  environments to accomplish goals, represent an  exciting  fro...\n",
      "\n",
      "> Object: 8b9503cd-c76c-47e2-9cdc-b8d7883876a9:\n",
      "\n",
      "##2.8 AI Agents\n",
      "\n",
      "For decades, the topic of AI agents has been widely discussed in the AI community, yet few benchmarks have achieved widespread adoption, including those featured in last year's Index...\n",
      "\n",
      "> Object: 261525a0-224d-4782-a23b-6736ad2bf673:\n",
      "\n",
      "##2.8 AI Agents Chapter 2: Technical Performance\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "VAB presents a signi fi cant challenge for AI systems. The topperforming model, GPT-4o, achieves an overall success rate of just 36.2...\n",
      "\n",
      "> Object: 1a3329ae-89af-468a-870b-147be4ec84a4:\n",
      "\n",
      "##VisualAgentBench\n",
      "\n",
      "VisualAgentBench  (VAB),  launched  in  2024,  represents  a signi fi cant step forward in the evaluation of agentic AI. This benchmark re fl ects the growing multimodality of AI ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Supporting passages:\")\n",
    "for o in response.objects:\n",
    "    print(f\"\\n> Object: {o.uuid}:\")\n",
    "    print(o.properties['chunk'][:200]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5845fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"build_git_commit\":\"08d409a988\",\"build_go_version\":\"go1.25.0\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.32.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-09-16T12:03:11+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-pdf-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
