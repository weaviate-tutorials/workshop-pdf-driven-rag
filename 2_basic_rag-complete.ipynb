{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5b434e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f86938",
   "metadata": {},
   "source": [
    "## Basic RAG with Weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5caf639",
   "metadata": {},
   "source": [
    "Now - let's try performing RAG with the chunks that we've created. \n",
    "\n",
    "We will:\n",
    "- Load & chunk a document\n",
    "- Add the chunks to Weaviate, and generate vectors\n",
    "- And perform RAG\n",
    "\n",
    "We assume some familiarity with Weaviate here. \n",
    "\n",
    "(If not, check out the [Weaviate Quickstart](https://docs.weaviate.io/weaviate/quickstart), or ask questions in the live session!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfefcb7",
   "metadata": {},
   "source": [
    "### Load and chunk a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2679d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_chunks_using_markers(src_text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split the source text into chunks using markers.\n",
    "    \"\"\"\n",
    "    marker = \"\\n##\"\n",
    "\n",
    "    # Split by marker and reconstruct with markers (except first chunk)\n",
    "    parts = src_text.split(marker)\n",
    "    chunks = []\n",
    "\n",
    "    # Add first chunk if it exists and isn't empty\n",
    "    if parts[0].strip():\n",
    "        chunks.append(parts[0].strip())\n",
    "\n",
    "    # Add remaining chunks with markers reattached\n",
    "    for part in parts[1:]:\n",
    "        if part.strip():\n",
    "            chunks.append(marker + part.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "md_file = Path(\"data/parsed/hai_ai_index_report_2025_chapter_2-parsed-text.md\")\n",
    "md_text = md_file.read_text(encoding=\"utf-8\")\n",
    "chunk_texts = get_chunks_using_markers(md_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5b1f4",
   "metadata": {},
   "source": [
    "### Set up Weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcf6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "# Use Embedded Weaviate with:\n",
    "# version: latest available (e.g. \"1.32.0\"), headers = {\"X-Cohere-Api-Key\": os.getenv(\"COHERE_API_KEY\")}, env vars: {\"LOG_LEVEL\": \"error\"}\n",
    "# BEGIN_SOLUTION\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.32.5\",\n",
    "    headers={\n",
    "        \"X-Cohere-Api-Key\": os.getenv(\"COHERE_API_KEY\"),\n",
    "    },\n",
    "    environment_variables={\n",
    "        \"LOG_LEVEL\": \"error\",  # Reduce amount of logs\n",
    "        \"ENABLE_API_BASED_MODULES\": \"true\"\n",
    "    }\n",
    ")\n",
    "# END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a68ec",
   "metadata": {},
   "source": [
    "### Set up a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac3093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"load_all_shards\",\"build_git_commit\":\"08d409a988\",\"build_go_version\":\"go1.25.0\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.32.5\",\"level\":\"error\",\"msg\":\"failed to load all shards: context canceled\",\"time\":\"2025-09-15T20:44:45+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "client.collections.delete(\"Chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bce4dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x1055f7550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.config import Property, DataType, Configure, Tokenization\n",
    "\n",
    "client.collections.create(\n",
    "    name=\"Chunks\",\n",
    "    properties=[\n",
    "        Property(\n",
    "            name=\"document_title\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk\",\n",
    "            data_type=DataType.TEXT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"chunk_number\",\n",
    "            data_type=DataType.INT,\n",
    "        ),\n",
    "        Property(\n",
    "            name=\"filename\",\n",
    "            data_type=DataType.TEXT,\n",
    "            tokenization=Tokenization.FIELD\n",
    "        ),\n",
    "    ],\n",
    "    vector_config=[\n",
    "        # Add `Configure.Vectors.text2vec_cohere` vector to the collection with:\n",
    "        # name: \"default\", source properties: [\"document_title\", \"chunk\"], and model: \"embed-v4.0\"\n",
    "        # BEGIN_SOLUTION\n",
    "        Configure.Vectors.text2vec_cohere(\n",
    "            name=\"default\",\n",
    "            source_properties=[\"document_title\", \"chunk\"],\n",
    "            model=\"embed-v4.0\"\n",
    "        )\n",
    "        # END_SOLUTION\n",
    "    ],\n",
    "    generative_config=Configure.Generative.cohere(\n",
    "        model=\"command-r\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f24e74",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a975565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = client.collections.get(\"Chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa01ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266it [00:00, 15875.99it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with chunks.batch.fixed_size(batch_size=100) as batch:\n",
    "    for i, chunk_text in tqdm(enumerate(chunk_texts)):\n",
    "        obj = {\n",
    "            \"document_title\": \"Stanford HAI Report 2025\",\n",
    "            \"filename\": \"data/pdfs/hai_ai_index_report_2025_chapter_2.pdf\",\n",
    "            \"chunk\": chunk_text,\n",
    "            \"chunk_number\": i + 1,\n",
    "        }\n",
    "\n",
    "        # Add object to batch for import with (batch.add_object())\n",
    "        # BEGIN_SOLUTION\n",
    "        batch.add_object(\n",
    "            properties=obj\n",
    "        )\n",
    "        # END_SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592d8f5",
   "metadata": {},
   "source": [
    "### RAG queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f8a81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query response:\n",
      "The benefits and use cases of agentic AI mentioned in the text include:\n",
      "\n",
      "- Agentic AI systems can assist with a diverse range of tasks, making them extremely versatile. These agents can help with academic research, scheduling, online shopping, and vacation booking.\n",
      "- They have the potential to navigate both virtual and embodied environments, extending beyond reliance on linguistic commands alone.\n",
      "- Agentic AI's ability to handle multimodality and interact with GUI and visual design tasks makes them valuable in many sectors.\n",
      "\n",
      "However, the complexity of benchmarking agentic tasks, which often involve dynamic and varied situations, makes their development and evaluation challenging. There's a need for effective methods to assess their performance accurately.\n"
     ]
    }
   ],
   "source": [
    "# Try a RAG query with:\n",
    "# query (what to search for): \"how to clean the washing machine\" and\n",
    "# grouped_task (prompt): \"Briefly, what tasks do I need to perform to regularly maintain and clean the washing machine?\"\n",
    "# limit (how many objects to fetch): 10\n",
    "# BEGIN_SOLUTION\n",
    "response = chunks.generate.hybrid(\n",
    "    query=\"Agentic AI use cases\",\n",
    "    limit=5,\n",
    "    grouped_task=\"Briefly, what use cases and benefits of agentic AI are mentioned here?\"\n",
    ")\n",
    "# END_SOLUTION\n",
    "\n",
    "print(\"Query response:\")\n",
    "print(response.generative.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cc6cbf",
   "metadata": {},
   "source": [
    "### Recap - what's happening under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d4730",
   "metadata": {},
   "source": [
    "![assets/llm_3_rag_weaviate.png](assets/llm_3_rag_weaviate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72249075",
   "metadata": {},
   "source": [
    "We can review the passages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a151a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supporting passages:\n",
      "\n",
      "> Object: 2d680701-09fd-46f4-a9df-803149b97d96:\n",
      "\n",
      "##Gemini 2.0 in an agentic work fl ow\n",
      "\n",
      "Source: AI Index, 2025\n",
      "\n",
      "<!-- image -->...\n",
      "\n",
      "> Object: 22ed7035-ede1-4542-b2e5-affb17c62ed3:\n",
      "\n",
      "##2.8 AI Agents Chapter 2: Technical Performance\n",
      "\n",
      "AI agents, autonomous or semiautonomous systems designed to operate within  speci fi c  environments to accomplish goals, represent an  exciting  fro...\n",
      "\n",
      "> Object: 741a1a05-70a9-428d-8fb8-529ceddafc40:\n",
      "\n",
      "##2.8 AI Agents\n",
      "\n",
      "For decades, the topic of AI agents has been widely discussed in the AI community, yet few benchmarks have achieved widespread adoption, including those featured in last year's Index...\n",
      "\n",
      "> Object: 6dc17834-1f10-4bd6-b5ab-a2dc2dfa91b6:\n",
      "\n",
      "##2.8 AI Agents Chapter 2: Technical Performance\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "VAB presents a signi fi cant challenge for AI systems. The topperforming model, GPT-4o, achieves an overall success rate of just 36.2...\n",
      "\n",
      "> Object: dfa91c2b-2ab9-4db2-9261-79a62606fe66:\n",
      "\n",
      "##VisualAgentBench\n",
      "\n",
      "VisualAgentBench  (VAB),  launched  in  2024,  represents  a signi fi cant step forward in the evaluation of agentic AI. This benchmark re fl ects the growing multimodality of AI ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Supporting passages:\")\n",
    "for o in response.objects:\n",
    "    print(f\"\\n> Object: {o.uuid}:\")\n",
    "    print(o.properties['chunk'][:200]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d5845fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"build_git_commit\":\"08d409a988\",\"build_go_version\":\"go1.25.0\",\"build_image_tag\":\"HEAD\",\"build_wv_version\":\"1.32.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2025-09-15T20:45:00+01:00\"}\n"
     ]
    }
   ],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-pdf-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
